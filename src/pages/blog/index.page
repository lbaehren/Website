---
title: "Blog"
in_menu: false
author: "Lars Baehren"
---

# {title:} #

**:::**

### Preparing to copy ###


_Tue, 16. December 2014 -- 21:00_

Ok, das kann mal noch eine Weile dauern, ehe es ueberhaupt so richtig losgeht:

![Finder window](/blog/2014/2014-12/2014-12-16_File_copy.png)

Heute Nachmittag habe ich hier im Institut eine groessere Sammlung an Festplatten
-- alle irgendwo zwischen 120 GB und 1 TB -- einsammeln koennen und diese zwecks
Weiterverwendung in das [Drobo](http://www.drobo.com/storage-products) gesteckt,
welches ich hier auf dem Schreibtisch stehen habe. Da ich zuletzt ja ein wenig
Schwierigkeiten mit der Festplatte hatte, auf welcher mein [Time Machine](http://support.apple.com/en-us/HT201250)
Backup liegt, hat es mich schon eine Weile gejuckt endlich einmal weg von der
Single-Disk Loesung zu kommen. Da ich das Drobo eh fuer diesen Zweck angedacht hatte,
es mir bisher aber leider immer noch an Festpatten mangelte, war dies heute natuerlich
eine willkommene Gelegenheit da endlich einmal taetig zu werden. Wie dies ja bei
(groesseren) Betrieben durchaus schon einmal ueblich ist (vor allen Dingen wenn die
ICT eine gewisse Groesse ueberschreitet), wird in regelmaessigen Abstaenden die
alte Computer-Ausruestung unter den Mitarbeitern verscherbelt -- so auch hier bei
[SRON](http://www.sron.nl). Ich hatte dem allerdings nicht sonderlich viel Beachtung
geschenkt, weil ich jetzt nicht unbedingt den Bedarf an alten Computern habe -- da
bedurfte es schon einer Rundmail...

> De verloting is weer klaar, maar ik heb nog wat oudere computers over.
> in de "oude bibliotheek" in de kelder kan je nog kijken of er nog iets voor je is.

... und einem etwas spaeteren Gespraech mit Tobias, um es bei mir klingeln zu lassen,
dass es sich ja nicht nur um komplette Rechnern, sondern auch um allerlei Bauteile
handeln kann. Also schnell mal runter und den Keller gerannt, um zu schauen was sich
dort noch so finden liess. Da ich mit meinem recht spezifischen Wunsch wohl ein wenig
ausserhalb dessen lag, was die meisten anderen haben wollten, hatte ich noch eine
groessere Kiste mit Festplatten zur Auswahl. Wirklich davon gebrauchen konnte ich
nur einen Teil -- weil ich eben nur mit SATA Platten etwas anfangen kann -- aber
ich bin doch mit einem recht ansehnlichen Stapel zurueck ins Buero gekommen. Aus diesem
Vorrat habe ich mir (erwartungsgemaess) die groessten Platten geschnappt und ins
Drobo eingebaut -- schon eine Weile her, dass ich dies zum letzten Mal gemacht habe
(seitdem die [Synology DiskStation](https://www.synology.com/en-global/products/DS2413+)
die Rolle des zentralen Datenhub uebernommen hat, hatten die Dobos bis auf weiteres
keine Aufgabe).

![Drobo disk pack](/blog/2014/2014-12/2014-12-16_Drobo_disk_pack.png)

Da ich vorhabe die einzelne Festplatte auszumustern -- oder zumindest an anderer Stelle
einzusetzen -- sollte ich erst einmal noch dafuer sorgen, dass die bisher darauf abgelegten
Daten auf das Drobo umkopiert werden. Statt dies (wie eigentlich ueblich) von der
Kommandozeile aus zu machen, habe ich die diversen Verzeichnisse ueber den Finder
durch die Gegend gezogen; waehrend die [Git](http://git-scm.com) Repositories recht
schnell kopiert waren, ist die _Time Machine_ Datenbank doch schon ein Stueck groesser.
Und waehrend ein Kommando wie `mv` oder `cp` sofort mit der Arbeit beginnt, inventarisiert
der Finder zunaechst erst einmal alles, was er dann anschliessend durch die Gegend
schiebt; alleine schon dieser erste Schritt kann mehrere Minuten dauern, bevor ueberhaupt
ein einzelnes Bit von A nach B bewegt wird. Angesichts der Tatsache, dass es gut
230 GB sind, welche via USB Verbindung durch die Gegend geschoben werden muessen...
da spiele sogar mit dem Gedanken den Rechner ausnahmsweise mal ueber Nacht im Institut
stehen zu lassen.

**:::**

### Drahtlos - kopflos ###


_Tue, 16. December 2014 -- 13:01_

Also einen entscheidenden Nachteil haben drahtlose Kopfhoerer schon: es ist ziemlich
leicht beim Verlassen des Hauses (der Wohnung) Dinge zurueck zu lassen. Erstaunlicherweise
sind davon bei mir aber nicht die Kopfhoerer selber betroffen, sondern ich neige eher
dazu das Handy nicht mitzunehmen/einzupacken. So war ich letzte Woche Montag schon ein
gutes Stueck aus dem Haus, als mit einem Male der Ton auf den Kopfhoerern zusammenbrach;
Da ih aber wusste dass alle Akkus aufgeladen waren, foerderte eine Inspektion der
Taschen schnell den Kern des Problems zu Tage. Heute Morgen dann ist es mir erst deutlich
spaeter aufgefallen (was vor allen Dingen daran lag, dass ich nicht Nachrichten gehoert
sondern in einem [TROPOMI](http://www.tropomi.eu) Dokument gelesen habe): ich stand
schon eine Weile an der Bushaltestelle, als ich bei dem Versuch nach der Urzeit zu schauen
feststellen durfte, dass wohl noch einmal ein Abstecher zurueck in die Wohnung faellig
werden wuerde. Was dies betrifft ist ein Kopfhoerer mit Kabel definitiv von Vorteil --
die Kombo zusammen mit dem Handy ist deutlich weniger leicht zu uebersehen und zu
vergessen.

**:::**

### Mit Hund unterwegs ###


_Mon, 15. December 2014 -- 22:20_

Schon suess, die Kleine! Dieses Foto habe ich nur wenige Minuten vor dem Zeitpunkt
gemacht, zu welchem Julias Yoga-Damen aus der [Atempause](https://plus.google.com/100836942898820199676/about)
gerannt kamen... und schnurgerade auf uns zukamen (und ich bin mir ziemlich sicher
bin, dass dies nichts mit mir zu tun hatte).

![Sofia](/blog/2014/2014-12/dsc_20141214_153447_Sofia.jpg)

Neben der Tatsache, dass man im Haus deutlich mehr aufpassen muss, was man so in der
Gegend herumliegen laesst -- will man es nicht verschleppt oder angekaut haben --
sind es nun wieder auch die regelmaessigen Ausfluege an die frische Luft, welche
als klarer Hinweis darauf gelten koennen, dass es wieder einen Hund im Haus gibt.
An diesem Sonntag ist es gerade einmal eine Woche, dass wir die kleine spanische
Hundedame in der Naehe von Frankfurt abgeholt haben... es ist aber schon zu erkennen,
wie sich alle Seiten aufeinander einstellen. Da sich das Wetter am Sonntag von der
sehr freundlichen Seite zeigte, war dies die (fast schon zu) perfekte Gelegenheit
fuer einen Spaziergang ueber die Felder in Richtung Roisdorf. Zumindest was einen Teil
der Strecke entspricht war dies die Tour, welche ziemlich genau eine Woche davor auch
schon gelaufen war -- da allerdings noch um mich mit Julia zu treffen und dann in
Richtung Frankfurt aufzubrechen. Diesen Sonntag war aber mehr Aufmerksamkeit fuer meine
Begleitung erforderlich, so dass die Motivsuche ein wenig in den Hintergrund treten
musste. Hat aber recht gut geklappt, so wir sogar mit ein wenig Zeitreserve bei der
Atempause angekommen sind.

**:::**

### Repair completed ###


_Mon, 15. December 2014 -- 08:00_

Das ist natuerlich eine Art von Benachrichtigung, wie ich sie gerne zu lesen bekomme:

> Dear user,
>
>
> The system has completed repairing the degraded storage space (Volume 1) with
Hot Spare disk (Disk 11).
>
>
> Sincerely,
> Synology DiskStation

Nachdem ich am letzten November-Wochenende zwei Festplatten in der [DiskStation](https://www.synology.com/en-global/products/DS2413+)
ausgetauscht habe, brauchte das System (erwartungsgemaess) eine Weile, um die Integritaet der
Daten wieder herzustellen und alles auf die neue Konfiguration abzustimmen. Da ich mir
aber vor einer Weile die Email-Benachrichtigung eingestellt hatte, kriege ich sogar
hier in Utrecht mit, dass sich zuhause abspielt (zumindest was die IT-Infrastruktur betrifft).
Dazu gehoert natuerlich auch, wenn eine der im NAS eingebauten Festplatten einen Fehler
aufweist:

> Dear user,
>
> The system is now using Hot Spare disk (Disk 11) to repair the degraded storage space (Volume 1).
>
> Sincerely,
> Synology DiskStation

Von den 12 Einschueben, welche zur Verfuegung stehen, werden lediglich 11 aktiv genutzt;
um die Verfuegbarkeit des Systems im Falle eines Festplattenfehlers sicherzustellen,
ist eine Platte als "Hot Spare" reserviert. Kommt es also zu einem Ausfall, dann kann
der Server direkt mit der Wiederherstellung der Daten beginnen, ohne dass ich dafuer
erst einmal eine neue Festplatte einbauen muss -- dies macht die ganze Sache einfach
deutlich entspannter.

**:::**

### Funktioniert wieder ###


_Thu, 11. December 2014 -- 21:49_

Das ich es je geschafft mir die Daten, welche ich zum arbeiten mitgenommen hatte,
durch einen doofen Programmierfehler zu zerschiessen (was bedeutet dass ich diese von
zuhause noch einmal uebertragen muss), konnte ich nicht wie geplant an dem Code fuer
die Generierung der Testdaten fuer meine Algorithmen arbeiten. Aus diesem Grunde habe
ich mich dann der Maschinerie hinter dem Blog zugewandt, welche einfach schon zu
lange ein paar recht wichtige Funktionalitaeten vermisst hat; dazu gehorte vor allen
Dingen der Zusammenbau der [Index-Seite fuer den Blog](/blog/index.html). Wie so
ueblich enthaelt diese Seite die letzten N Eintraege in chronologisch umgekehrter Folge
-- worauf sich dann auch die Aufgabe ableiten laesst, welche es zu loesen gibt. Einen
Teil davon hatte ich ja bereits (neu und kompakter) implementiert, aber was mir eben
noch fehlte war der letzte Schritt, naemlich aus der Liste der letzten Eintraege die
Seite zusammenzubauen. Einen nicht unerheblichen Teil davon konnte ich von der Routine
verwenden, welche fuer den Index der in Vorbereitung befindlichen Eintraege zustaendig
ist -- der wesentliche Unterschied ist allerdings dass ich nicht nur die Ueberschriften
sondern auch den vollen Text brauche.

In der Verhangenheit hatte dies mitunter zu einigen merkwuerdigen Resulaten gefuehrt,
weil ich via diverser `grep` Statements probiert habe sowohl den Header als auch andere
Metadaten herauszufiltern. Wenn dann einer der Patterns auch im Text des Blog-Eintrages
auftauchte, konnte es durchaus schon einmal passieren, dass vereinzelte Passagen
verschluckt wurden. Damit duerfte nun aber Schluss sein -- und dies mit einem
Bruchteil an Code!

Mit zu verdanken habe ich dies dem [Advanced Bash-Scripting Guide](http://www.tldp.org/LDP/abs/html),
einer Sammlung an Anleitungen und Ausfuehrungen, welche mir schon so manches Mal
beim Scripten geholfen hat. Der Ausgangspunkt meiner Ueberlegungen war, dass ich
es via `sed` schaffen sollte einfach den kompletten Header abzuschneiden, so das
ich mir alle weiteren Verrenkungen mit `grep` sparen kann. Da mein Wissen in
Sachen "Regular Expressions" sich doch immer wieder als ein wenig lueckenhaft
herausstellt, war da der Zeitpunkt gekommen, einmal wieder den Guide zu Hand zu
nehmen. Praktischerweise findet sich darin gegen Ende ein "Sed and Awk
Micro−Primer", wo ich dann den folgenden Befehl finden konnte:

~~~~~~~~
sed 11,/^$/d
~~~~~~~~

Als Beschreibung hierzu hiess es:

> Delete from beginning of input up to, and including first blank line.

Das kam der Sache schon ziemlich nahe und lieferte auf Anhieb gleich ein Ergebnis,
welches ich verwenden konnte: einfach die entsprechende Datei via `cat` ausgeben lassen
und dann in `sed` pipen.

~~~~~~~~
cat $1 | sed 11,/^$/d
~~~~~~~~

An der Stelle ist mir dann aufgefallen, dass sich dies sogar noch ein wenig mehr verbessern
laesst, indem ich nicht nach der ersten Leerzeile, sondern nach der eh herauszufilternden
Titelzeile suche (weil diese eh anders aufbereitet werden muss). Einfach mal schnell
ausprobieren...

~~~~~~~~
cat $1 | sed 1,/"##"/d
~~~~~~~~

... und siehe da, schon habe ich ein fertiges Script, welches nir die Index-Seite fuer den
Blog produziert. Das schoene daran ist, dass dies mit deutlich weniger Code und deutlich
weniger Anfaelligkeit gegenueber dem was im Eintrag selber steht geschieht (wo es in der
Vergangenheit naemlich durchaus schon einmal Probleme gab). Damit kann also der Blog fuer
das erste **endlich** wieder online gehen!

**:::**

### Daten weg ###


_Thu, 11. December 2014 -- 18:12_

So kann man sich natuerlich auch selber sabotieren: durch die Verwechslung eines
Dateinamens habe ich mir (noch vor Arnhem) die Daten gekillt, welche ich mir noch
extra fuer die Reise auf das Laptop geschaufelt hatte. Zunaechst dachte ich, dass
ich mit den Code selber zu weit gegangen bin - zu viele Schritte ohne zwischenzeitliches
Backup -- aber nach ein wenig Suche stellte sich heraus, dass der Code (weitestgehend)
ok war... sieht man einmal von der Tatsache ab, dass ich an einer Stelle den falschen
Pfad verwendet habe. Der Effekt von dieser Aktion war, dass ich eben genau jene
Daten ueberschrieben habe, welche ich zum Testen verwenden wollte. Sieht also ganz
danach aus, als kann ich mir zumindest dieses Vorhaben fuer die Rueckfahrt abschreiben.

**:::**

### Wieder einen Schritt naeher ###


_Wed, 10. December 2014 -- 22:23_

Und doch endlich wieder einmal einen kleinen Schritt weiter. Waehrend ich in der
Zwischenzeit durchaus ein paar wenige Eintraege geschrieben habe, ist die Infrastruktur
immer noch nicht auf dem Stand, dass ich ohne weiteres den Blog mit allen dazu
gehoerenden Seiten aktualisieren kann. Was mir derzeit noch fehlt ist, dass die
Index-Seiten und die Seite mit den letzten Eintraegen aufs Neue gebaut werden; zumindest
was letzteres betrifft habe ich nun einen kleinen Fortschritt machen koennen:

~~~~~~~~
    for FILE in `ls ${PATH_BASEDIR}`
    {
        if [ -d "$FILE" ]
        then
            find $FILE -name "*.page" | grep -v index | grep -v upcoming >> ${tmpFile}
        fi
    }

    # Sort through the list of entries
    varEntries=`cat ${tmpFile} | tail -n ${nofEntries} | sort -r`
~~~~~~~~

Derzeit spuckt die Routine nur eine Liste mit den wesentlichen Eigenchaften der
Eintraege aus, aber der folgende Schritt darauf eine Seite zu basteln duerfte
(zumindest hoffe ich dies) nicht mehr so schwer sein.

Rein von der technischen Seite her bin ich mit dem bisher erstellten recht zufrieden:
was ich bis jetzt am Laufen habe ist deutlich modularer was die einzelnen Schritte
betrifft, welche es auszufuehren gibt. Dadurch dass alles als ein Bash Script geschrieben
ist, gibt es zwar nicht die gleiche Art der Modularisierung, wie die dies z.B. bei
C++ kriegen wuerde, aber da es eben nicht einfach nur ein gigantisches Script ist,
kann ich die einzelnen Teile auf immer wieder neue Weise zusammenfuegen. Dabei gibt
es einfach ein paar Standardaufgaben, welche man einmal implementieren sollte... und
dann ist es aber auch gut damit. Was jetzt aber noch ansteht ist, dass ich mir noch
einmal ein wenig Zeit dafuer reserviere, um alle Bauteile zusammenzufuegen und die
Index-Seiten auch wirklich wieder zu generieren. Wenn dies der Fall ist, steht den
regelmaessigen Updates nichts mehr im Weg.

**:::**

### Listing blog entries ###


_Thu, 04. December 2014 -- 19:56_

While some of the machinery is not back online again, I am making some progress
on streamlining the tools supposed to be working behind the scenes. Given the fact
that the current routine to list the contents of a directory (in terms of available
blog entries) now already is an improvement w.r.t. the older version, generalising
it a little it further only seemed like a logical step. The first iteration specifically
had been written with the idea in mind to list upcoming entries (and offer them
for publication); however extraction of further details was pretty generic, such
that the only thing left to adjust was the path w.r.t. which the listing was extracted.

~~~~~~~~
list_entries ()
{
    if [ -z $1 ] ; then
        varDirectory=${PATH_UPCOMING}
    else
        varDirectory=$1
    fi

    cd ${PATH_BASEDIR}

    for FILE in `ls ${varDirectory} | grep -v index.page`
    {
        varTitle=`get_entry_title ${varDirectory}/${FILE}`
        varTimeheader=`get_timeheader ${varDirectory}/${FILE}`
        echo " - ${FILE} | ${varTitle} | ${varTimeheader}"
    }
}
~~~~~~~~

The default behaviour has been kept, such that if now further argument is provided,
the contents of the directory with entries in preparation is listed.

**:::**

### Ablehnungsreflexe ###


_Thu, 04. December 2014 -- 09:34_

 Manchmal bin ich dann doch noch verwundert ueber das, was ich so bei einem
Radiointerview zu hoeren kriegen. Angesichts der diese Woche noch anstehenden
Wahl des Ministerpraesidenten von Thueringen hat die dortige CDU die Order
gegeben "alles zu tun dass Bodo Ramelow nicht gewaehlt" wird. Von der Fixierung
her auf dieses Ziel muss ich sofort an die Vorgehensweise der Republikaner in
den USA stattfinden: statt zu versuchen einen Gegenentwurf vorzustellen
definitiert man sich eigentlich nur noch ueber Fundamentalopposition zum
politischen Mitbewerber. Das einzig verbleibende humoristische an der Situation
ist, dass es durch das grosse Ausschliessen -- welche mitterweile in beide
Richtungen des politischen Spektrums anzutreffen ist -- immer absurder wird.
Vielleicht sollte man den armen CDU Politikern in Thueringen schon einmal
politisches Asyl in einem anderen Bundesland anbieten ;)

**:::**

### Kein guter Start ###


_Mon, 01. December 2014 -- 07:47_

Irgendwie setzt sich die Pannenserie fort... Nachdem ich heute Morgen zuhause schon
so manche Probleme mit der Koordination meiner morgendlichen Taetigkeiten hatte --
so ist es mir gelungen mein Handy in die Kueche liegen lassen, was mir gleucklicherweise
dadurch aufgefallen ist, dass das Signal auf dem Kopfhoerer zusammenbrach -- scheine
ich nun auch mit dem ICE Probleme zu kriegen. Waehrend es in Koeln noch recht glatt
werden wir nun erst einmal gut 30 Minuten bis zur Weiterfahrt warten muessen. Die
Tatsache, dass ein technischer Fehler am Zug als Grund angegeben wurde, stimmt mich
allerdings nicht so hoffnungsvoll, denn dies kann auch durchaus bedeuten, dass dieser
ICE komplett eingestellt wird und ich mich mit einer anderen Verbindung nach Utrecht
durchschlagen muss. Nicht, dass ich da allzu pessimistische Stimmung verbreiten wollte,
aber mittlerweile habe ich nun doch ausreichend viele Bahnfahrten hinter mich gebracht,
dass mir bestimmte Ablaeufe durchaus bekannt sind.

**:::**

### Zu anderer Zeit ###


_Thu, 27. November 2014 -- 19:45_

Da muss ich wirklich aufpassen, wenn ich dies in Zukunft oefters machen will; ich bin
mittlerweile so auf den ICE um 19:02 Uhr eingeschossen, so dass durchaus ein Risiko
bestand, dass ich noch rechtzeitig aus dem Institut verschwinde. Da ich meine Reiseplanungen
ein wenig in die Richtung versuche anzupassen, dass ich frueher am Abend in Bonn bin
-- sonst wird es typischerweise nach Mitternacht, ehe ich wirklich im Bett bin.
Netterweise frequentiert der ICE zwischen Amsterdam und Frankfurt ja im 2-Stunden Takt,
so dass ich jetzt einfach mal die Verbindung um 17:00 Uhr austesten werde -- da muss
sich noch zeigen, in wie weit dies gegenueber der spaeteren Verbindung wirklich ein
Vorteil ist. Einen recht grossen Einfluss auf das Vorankommen hat natuerlich -- wie dies
ja so ueblich ist -- wie es mit dem Transfer vom Uithof zum Bahnhof aussieht; ich musste
eben schon feststellen, dass die Linie 12 zwar enger getaktet ist, dafuer aber die
Linie 28 (welche ich gerne schon einmal als Alternative verwende) erst nach 17 Uhr
wieder verkehrt. Aber gut, ich werde dies jetzt mal eine Weile testen, denn nur von
einem Mal ist mit Sicherheit kein vernuenftiges Urteil moeglich.

**:::**

### Wieder in Utrecht ###


_Mon, 22. September 2014 -- 22:45_

Da hat mich Utrecht wieder. Nachdem in der vergangenen Woche -- nun auch einmal
fuer mich -- eine etwas intensiere Arbeitsphase im Haus auf dem Programm stand,
muss ich mich nun wieder darum kuemmern, dass es mit der Fertigstellung der Software
fuer die TROPOMI On-ground Calibration (OCAL) klappt. Hat natuerlich nach der
Abwesenheit ein wenig gedauert, bis ich wieder Fuss gefasst habe; aus diesem Grunde
habe ich mir zunaechst einmal die Aufgaben geschnappt, welche eher begrenzt vom
Umfang und recht gut definiert sind. Nach dieser "Aufwaermuebung" kann ich mich dann
an die Dinge begeben, welche ein wenig mehr Zeit und Kontinuitaet erfordern.

**:::**

### In Koeln ###


_Thu, 11. September 2014 -- 21:25_

Da bin ich also mal wieder in Koeln. Auch wenn dies fuer sich genommen garnicht
einmal so sonderlich erwaehnenswert ist, so ist der heutige Zwischenstop erst
einmal der letzte fuer die naechsten zehn Tage; kommende Woche bleibe ich ja in
Bonn, damit wir uns an den Einbau der Heizung machen koennen -- da steht also kein
Trip nach Utrecht auf dem Plan. Um aber zumindest indirekt ein wenig Arbeit abliefern
zu koennen habe ich einen Teil der Fahrt noch damit zugebracht an dem Script zu
basteln, mit welchem ich (so hoffe ich doch mal) in der Lage sein duerfte die
Timing-Informationen fuer die Quicklooks zu extrahieren, auf welche ich Matthijs
diese Woche wohl neugierig gemacht habe. Eigentlich waren die Zahlen ja eher so ein
Nebenprodukt meiner wiederkehrenden Runs der OCAL Framework Tasks, aber da es
ein wenig darum geht Funktionalitaet fuer die Kalibrationsmessung zu buendeln,
ist es nun durchaus relevant wie lange welche Processing-Steps brauchen.

Wo ich unterwegs noch eine Weile dran geknabbert habe ist, wie ich die Ausgabe
der ``time`` Utility angefangen kriege; was mich bei den bisherigen Runs ja
immer gestoert hat ist, dass die Timing-Information immer irgendwo in den
munter weiter-scrollenden Log-Messages auftauchte -- ziemlich laestig, wenn man
plant Tasks gleich dutzendweise laufen zu lassen. Entscheidend ist es hier
die Standard-Streams noch **vor** dem Aufruf von ``time`` umzubiegen, so laesst
sich dann die entsprechende Ausgabe abfangen und in einer Datei wegschreiben.

~~~~
&>task.log time ${RUNTASK} -s 123456 quicklooks/${GROUP}/${FILE}/${TASK}.ocal
~~~~

Fuegt man dann noch ein wenig ``tr`` und ``sed`` Magic hinzu, so erhaelt man
ein Logfile, in welchem alle gewuenschten Informationen zu finden sind:

~~~~
=====================================================================
proc_raw:['0.44', '0.28', '0.15']
=====================================================================
proc_raw:['0.43', '0.28', '0.14']
=====================================================================
proc_raw:['0.43', '0.28', '0.14']
=====================================================================
proc_raw:['0.44', '0.29', '0.14']
=====================================================================
quicklook_raw:['0.43', '0.28', '0.15']
=====================================================================
quicklook_raw:['0.43', '0.28', '0.14']
=====================================================================
~~~~

Wendet man hierauf noch ein weiteres Mal eine Kombination von ``grep`` und
``sed`` an, dann erhaelt man eine Ausgabe, welche gueltigem Python-Code
(eine Liste) entsprechen:

~~~~
['0.43', '0.28', '0.15']
['0.43', '0.28', '0.14']
['0.42', '0.28', '0.14']
['0.43', '0.28', '0.14']
['0.43', '0.28', '0.14']
['0.42', '0.27', '0.14']
~~~~

Bin ich mal gespannt, ob alles so funtioniert, wie ich mir dies vorgestellt
habe; meine Erwartung ist schon, dass der Rechner im [KNMI](http://www.knmi.nl)
einige Stunden beschaeftigt sein wird -- ist der Rest aber ok, dann kann ich
einfach den Job laufen lassen und anschliessend einfach nur die Logs einsammeln,
in welchen die Zahlen fuer die gewuenschten Statistiken zu finden sind.

**:::**

### Feueralarm ###


_Tue, 09. September 2014 -- 20:19_

Das hatte ich bisher auch noch nicht.. Waehrend ich bei [ASTRON](http://www.astron.nl)
durchaus einige Male aus der Arbeit gerissen wurde, um aufgrund eines Feueralarms das
Gebaeude zu verlassen, ist mir dies hier bei [SRON](http://www.sron.nl) noch nicht
vorgekommen. Vorhin -- gerade einmal ein paar Minuten nach Beginn des [Apple](http://www.apple.com)
Special Event -- ging hier auf der ersten Etage der Alarm los. Da wir uns ausserhalb
der normalen Arbeitszeiten befanden, war die Wahrscheinlichkeit einer Uebung recht
gering. Also mal schnell das Laptop in den Rucksack gestopft und in Richtung Rezeption
losgesteifelt; noch bevor ich allerdings dort ankam, bildete sich bereits eine kleine
Gruppe hier auf dem Gang, welche sich daran machte der Ursache des Alarms nachzugehen.
Da war aber nichts zu sehen, so dass die Versammlung sich in Richtung Ausgang verschob.
Dort angekommen konnte sich immer niemand so wirklich zum Verlassen des Gebaeudes
aufraffen, weil von der ganzen Indizienlage her einfach recht unwahrscheinlich war,
dass es sich um einen wirklichen Brandalarm handelte. Die ersten, welche von ausserhalb
eintraffen, waren die Leute vom Sicherheitsdienst, erst ein paar Minuten spaeter
gefolgt von einem Loeschwagen der Feuerwehr. Da alles wenig nach einem Notfall aussah,
habe ich die Zeit in der Eingangshalle einfach noch ein wenig zum Arbeiten genutzt
-- netterweise war meine Remote-Verbindung ins [KNMI](http://www.knmi.nl) durch das
Schliessen des Rechners nur eingefroren, aber nicht zusammengebrochen, so dass ich
sogar direkt in dem Editor-Fenster weitermachen konnte.

Insgesamt hat die ganze Aktion vielleicht eine halbe Stunde gedauert, dann habe ich
mich mich aber auch schon wieder aufgemacht zurueck in Richtung Buero. Ich haette
natuerlich auch einfach die Gelegenheit nutzen koennen und mich in Richtung Wohnung
abzusetzen, aber da ich a) noch einen frisch aufgebruehten Becher Tee auf dem Schreibtisch
stehen hatte und b) ich noch eine Weile den grossen Monitor ausnutzen wollte, schien
es mir einfach das Beste die Zeit bis zum letzten Bus in Richtung Hoograve noch am
Arbeitsplatz auszunutzen.

**:::**

### Zu Gast bei Veronica Mars ###


_Thu, 04. September 2014 -- 21:36_

Nachdem ich ja [Anfang dieser Woche](/blog/2014/2014-09/2014-09-02_20-43.html) mit
der letzten Folge von [Odyssey 5](http://www.imdb.com/title/tt0318236) fertig geworden
bin, habe ich mich recht unmittelbar auf die Season zwei von [Veronica Mars](http://www.imdb.com/title/tt0412253)
gestuerzt. Die Serie sitzt mir (wie man zumindest ein Stueck weit auch anhand der
Taskwarrior-Eintraege erkennen kann) schon eine ganze Weile im Nacken...und die
Tatsache dass da in diesem Jahr auch noch ein Film hinzugekommen ist, hat die Sache
eigentlich nur noch "schlimmer" gemacht.

~~~~
Year Month     Added Completed Deleted Net
____ _________ _____ _________ _______ ___
2011 December     19        17       0   2
2012 January      11         5       5   1
     June          1         1       0   0
     August        3         2       0   1
2013 March         5         9       0  -4
2014 January       1         0       0   1
     March         1         1       0   0
     April        42         0       0  42
     September     0         9       0  -9
~~~~

Was ich mir aber zumindest vorgenommen hatte war, dass ich mich nicht an den Film
begebe, wenn ich vorher nicht alle drei Seasons komplett durchgeschaut habe; Season
eins liegt schon eine ganze Weile zurueck und auch bei Season drei bin ich schon
durchgeszappt -- dazwischen ist aber irgendwie Niemandsland, so dass ich mich nun
daran gemacht habe diese Weisen Flecken auf der Karte mit Inhalt zu fuellen. Laesst
sich alles recht erfolgreich an, unter anderem auch weil ich es schaffe einige der
eher langweiligen Taetigkeiten (zumindest was die Aufmerksamkeit betrifft) mit dem
dem gucken (bzw. hoeren) zu kombinieren.

Als ich bei [Season 2, Episode 6](http://www.imdb.com/title/tt0739539) angelangt bin,
habe ich aber mehrfach hinschauen muessen... vorwiegend, weil ich einfach meinen Augen
nicht trauen wollte. Wie aber eine schnelle Recherche in der [Internet Movie Database](http://www.imdb.com)
ergab (ich wollte nicht bis zum Abspann warten), hatte da in der Tat [Joss Whedon](http://www.imdb.com/name/nm0923736)
einen Gastauftritt in der Serie. Eigentlich ist der Mann ja eher dafuer bekannt sich
hinter der Kamera -- oder gar hinter Schreibmaschine bzw. Computer -- aufzuhalten,
aber bei ein paar Gelegenheiten scheint er da wohl mal eine Ausnahme gemacht zu haben.
So komt es also, dass der Schoepfer von [Firefly](http://www.imdb.com/title/tt0303461),
[Dollhouse](http://www.imdb.com/title/tt2376425) (nur um mal die ersten Dinge zu nennen,
welche mir da einfallen), hier einen recht schleimigen und gelangweilten Chef einer
Leihwagenfirma spielt. Durchaus eine witzige Ueberraschung.
